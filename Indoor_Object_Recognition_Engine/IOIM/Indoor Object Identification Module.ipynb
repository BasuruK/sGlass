{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nipuni\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam,adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Negative', 'Positive']\n",
      "Loaded the images of dataset-Negative\n",
      "\n",
      "['Negative', 'Positive']\n",
      "Loaded the images of dataset-Positive\n",
      "\n",
      "Image Data (234, 49152)\n",
      "Image Data Scaled [[-0.06999187 -0.06604903 -0.03929729 ..., -0.16223969 -0.11872931\n",
      "  -0.07215629]\n",
      " [-0.35696729 -0.39779527 -0.38733662 ...,  0.39891226  0.28597075\n",
      "   0.34767629]\n",
      " [-0.09049011 -0.02702006 -0.05761515 ..., -0.11907416 -0.24013933\n",
      "  -0.4189745 ]\n",
      " ..., \n",
      " [-0.60294623 -0.78808498 -0.73537595 ...,  2.79459946  2.91652113\n",
      "   2.84841817]\n",
      " [-0.02899538 -0.18313594 -0.13088659 ..., -1.06871593 -1.04953945\n",
      "  -0.96658222]\n",
      " [-0.50045501 -0.45633873 -0.3507009  ...,  0.33416396  0.42761577\n",
      "   0.45719783]]\n",
      "Image Data Scaled RGB (234, 128, 128, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nipuni\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(128, 128,..., padding=\"same\")`\n",
      "C:\\Users\\Nipuni\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:99: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "C:\\Users\\Nipuni\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:102: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), data_format=\"channels_first\")`\n",
      "C:\\Users\\Nipuni\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:105: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 126, 63, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 126, 63, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 64, 61, 14)        72640     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 64, 61, 14)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 64, 30, 7)         0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 64, 30, 7)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 13440)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               6881792   \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 6,965,602.0\n",
      "Trainable params: 6,965,602.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Test Loss: 6.17288732529\n",
      "Test accuracy: 0.617021262646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os.path\n",
    "from keras.models import load_model\n",
    "\n",
    "USE_SKLEARN_PREPROCESSING=False\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def image_to_feature_vector(image,size=(128,128)):\n",
    "    #resize the image to a fixed size , then flttern the image into a list of raw pixels intensities\n",
    "    return cv2.resize(image,size).flatten()\n",
    "\n",
    "if USE_SKLEARN_PREPROCESSING:\n",
    "    img_data=img_data_scaled\n",
    "    \n",
    "PATH = os.getcwd()\n",
    "# Define data path\n",
    "data_path = PATH + '\\Original\\DATA SET'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "img_rows=128\n",
    "img_colms=128\n",
    "num_channels=3\n",
    "num_epoch=6\n",
    "\n",
    "img_data_list=[]\n",
    "for dataset in data_dir_list:\n",
    "    print(data_dir_list)\n",
    "    img_list=os.listdir(data_path+'/'+dataset)\n",
    "    print('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    for img in img_list:\n",
    "        input_img=cv2.imread(data_path+'/'+dataset+'/'+img)\n",
    "            \n",
    "        input_img_flatten=image_to_feature_vector(input_img,(128,128))\n",
    "            \n",
    "        img_data_list.append(input_img_flatten)\n",
    "\n",
    "img_data=np.array(img_data_list)\n",
    "img_data=img_data.astype('float')\n",
    "print('Image Data',img_data.shape)\n",
    "\n",
    "if num_channels==1:\n",
    "    if K.image_dim_ordering()=='th':\n",
    "        img_data=np.expand_dims(img_data,axis=1)\n",
    "        print('Image Data BnW',img_data.shape)\n",
    "    else:\n",
    "        img_data=np.expand_dims(img_data,axis=4)\n",
    "        print('Image Data BnW',img_data.shape)\n",
    "\n",
    "else:\n",
    "    if K.image_dim_ordering()=='th':\n",
    "        img_data=np.rollaxis(img_data,3,1)\n",
    "        print('Image Data RGB',img_data.shape)\n",
    "\n",
    "image_data_scaled=preprocessing.scale(img_data)\n",
    "print(\"Image Data Scaled\" , image_data_scaled)\n",
    "\n",
    "if K.image_dim_ordering()=='th':\n",
    "    image_data_scaled=image_data_scaled.reshape(img_data.shape[0],num_channels,img_rows,img_colms)\n",
    "    print('Image Data Scaled BnW',image_data_scaled.shape)\n",
    "else:\n",
    "    image_data_scaled=image_data_scaled.reshape(img_data.shape[0],img_rows,img_colms,num_channels)\n",
    "    print('Image Data Scaled RGB',image_data_scaled.shape)\n",
    "\n",
    "#Define classes\n",
    "\n",
    "num_classes=2\n",
    "\n",
    "num_samples=img_data.shape[0]\n",
    "labels=np.ones((num_samples,),dtype='int64')\n",
    "\n",
    "labels[0:113]=0\n",
    "labels[113:]=1\n",
    "\n",
    "names=['negative','positive']\n",
    "\n",
    "#convert class labels to on-hot encoding\n",
    "Y=np_utils.to_categorical(labels,num_classes)\n",
    "\n",
    "x,y=shuffle(img_data,Y,random_state=2)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=4)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_colms, img_rows, -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_colms, img_rows, -1)\n",
    "\n",
    "input_shape=(img_colms, img_rows, 1)\n",
    "\n",
    "# Defining the model\n",
    "input_shape=img_data[0].shape\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3),border_mode='same',input_shape=(128,128,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32,( 3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering='th'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),dim_ordering='th'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering='th'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512)) #no of hidden layers\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "# Viewing model_configuration\n",
    "\n",
    "model.summary()\n",
    "model.get_config()\n",
    "model.layers[0].get_config()\n",
    "model.layers[0].input_shape\n",
    "model.layers[0].output_shape\n",
    "model.layers[0].get_weights()\n",
    "np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable\n",
    "\n",
    "# Training\n",
    "\n",
    "if os.path.isfile('Hand_Gesture_Recognition.h5') == False:\n",
    "    hist = model.fit(X_train, y_train, batch_size=150, epochs=num_epoch, verbose=1, validation_data=(X_test, y_test))\n",
    "    model.save('Hand_Gesture_Recognition.h5')\n",
    "else:\n",
    "    hist=load_model('Hand_Gesture_Recognition.h5')\n",
    "\n",
    "# Evaluating the model\n",
    "\n",
    "score = model.evaluate(X_test, y_test, batch_size=150 , verbose=0) #batch_size=16\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "test_image = X_test[0:1]\n",
    "\n",
    "#print(model.predict(test_image))\n",
    "#print(model.predict_classes(test_image))\n",
    "y_test[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam,adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bottel', 'Mug']\n",
      "Loaded the images of dataset-Bottel\n",
      "\n",
      "['Bottel', 'Mug']\n",
      "Loaded the images of dataset-Mug\n",
      "\n",
      "Image Data (62, 49152)\n",
      "Image Data Scaled [[ 0.09749877  0.00846097 -0.01181566 ..., -0.07870336 -0.24681796\n",
      "  -0.41459091]\n",
      " [ 0.12898275 -0.02502287 -0.1720656  ..., -0.97143837 -1.2095344\n",
      "  -1.40772458]\n",
      " [-0.01794248 -0.03618415  0.07975573 ..., -0.62651802 -0.73937056\n",
      "  -0.71837297]\n",
      " ..., \n",
      " [ 0.88459823  0.82323449  0.80088045 ...,  1.07779426  1.05172979\n",
      "   0.95242839]\n",
      " [ 0.88459823  0.82323449  0.80088045 ...,  1.07779426  1.05172979\n",
      "   0.95242839]\n",
      " [ 0.87410357  0.81207321  0.78943403 ..., -0.49463672 -0.1796517\n",
      "   0.36823211]]\n",
      "Image Data Scaled RGB (62, 128, 128, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nipuni\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(128, 128,..., padding=\"same\")`\n",
      "C:\\Users\\Nipuni\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:100: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "C:\\Users\\Nipuni\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:103: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), data_format=\"channels_first\")`\n",
      "C:\\Users\\Nipuni\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:106: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 126, 63, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 126, 63, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 61, 14)        72640     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 64, 61, 14)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 64, 30, 7)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64, 30, 7)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 13440)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               6881792   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 6,965,602.0\n",
      "Trainable params: 6,965,602.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Test Loss: 6.19926738739\n",
      "Test accuracy: 0.615384638309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os.path\n",
    "from keras.models import load_model\n",
    "\n",
    "USE_SKLEARN_PREPROCESSING=False\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def image_to_feature_vector(image,size=(128,128)):\n",
    "    #resize the image to a fixed size , then flttern the image into a list of raw pixels intensities\n",
    "    return cv2.resize(image,size).flatten()\n",
    "\n",
    "if USE_SKLEARN_PREPROCESSING:\n",
    "    img_data=img_data_scaled\n",
    "    \n",
    "PATH = os.getcwd()\n",
    "\n",
    "# Define data path\n",
    "data_path = PATH + '\\Indoor Objects\\DATA SET'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "img_rows=128\n",
    "img_colms=128\n",
    "num_channels=3\n",
    "num_epoch=6\n",
    "\n",
    "img_data_list=[]\n",
    "for dataset in data_dir_list:\n",
    "    print(data_dir_list)\n",
    "    img_list=os.listdir(data_path+'/'+dataset)\n",
    "    print('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    for img in img_list:\n",
    "        input_img=cv2.imread(data_path+'/'+dataset+'/'+img)\n",
    "            \n",
    "        input_img_flatten=image_to_feature_vector(input_img,(128,128))\n",
    "            \n",
    "        img_data_list.append(input_img_flatten)\n",
    "\n",
    "img_data=np.array(img_data_list)\n",
    "img_data=img_data.astype('float')\n",
    "print('Image Data',img_data.shape)\n",
    "\n",
    "if num_channels==1:\n",
    "    if K.image_dim_ordering()=='th':\n",
    "        img_data=np.expand_dims(img_data,axis=1)\n",
    "        print('Image Data BnW',img_data.shape)\n",
    "    else:\n",
    "        img_data=np.expand_dims(img_data,axis=4)\n",
    "        print('Image Data BnW',img_data.shape)\n",
    "\n",
    "else:\n",
    "    if K.image_dim_ordering()=='th':\n",
    "        img_data=np.rollaxis(img_data,3,1)\n",
    "        print('Image Data RGB',img_data.shape)\n",
    "\n",
    "image_data_scaled=preprocessing.scale(img_data)\n",
    "print(\"Image Data Scaled\" , image_data_scaled)\n",
    "\n",
    "if K.image_dim_ordering()=='th':\n",
    "    image_data_scaled=image_data_scaled.reshape(img_data.shape[0],num_channels,img_rows,img_colms)\n",
    "    print('Image Data Scaled BnW',image_data_scaled.shape)\n",
    "else:\n",
    "    image_data_scaled=image_data_scaled.reshape(img_data.shape[0],img_rows,img_colms,num_channels)\n",
    "    print('Image Data Scaled RGB',image_data_scaled.shape)\n",
    "\n",
    "#Define classes\n",
    "\n",
    "num_classes=2\n",
    "\n",
    "num_samples=img_data.shape[0]\n",
    "labels=np.ones((num_samples,),dtype='int64')\n",
    "\n",
    "labels[0:33]=0\n",
    "labels[33:63]=1\n",
    "\n",
    "names=['bottel','mug']\n",
    "\n",
    "#convert class labels to on-hot encoding\n",
    "Y=np_utils.to_categorical(labels,num_classes)\n",
    "\n",
    "x,y=shuffle(img_data,Y,random_state=2)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=4)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_colms, img_rows, -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_colms, img_rows, -1)\n",
    "\n",
    "input_shape=(img_colms, img_rows, 1)\n",
    "\n",
    "# Defining the model\n",
    "input_shape=img_data[0].shape\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3),border_mode='same',input_shape=(128,128,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32,( 3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering='th'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),dim_ordering='th'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering='th'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512)) #no of hidden layers\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "# Viewing model_configuration\n",
    "\n",
    "model.summary()\n",
    "model.get_config()\n",
    "model.layers[0].get_config()\n",
    "model.layers[0].input_shape\n",
    "model.layers[0].output_shape\n",
    "model.layers[0].get_weights()\n",
    "np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable\n",
    "\n",
    "# Training\n",
    "\n",
    "if os.path.isfile('Indoor_Object_Recognition.h5') == False:\n",
    "    hist = model.fit(X_train, y_train, batch_size=150, epochs=num_epoch, verbose=1, validation_data=(X_test, y_test))\n",
    "    model.save('Indoor_Object_Recognition.h5')\n",
    "else:\n",
    "    hist=load_model('Indoor_Object_Recognition.h5')\n",
    "\n",
    "# Evaluating the model\n",
    "\n",
    "score = model.evaluate(X_test, y_test, batch_size=150 , verbose=0) \n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "test_image = X_test[0:1]\n",
    "\n",
    "y_test[0:1]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing a new image\n",
    "def Get_Reult_Of_HG(filepath):\n",
    "\n",
    "    test_image = cv2.imread(filepath)\n",
    "    #test_image=cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "    test_image=cv2.resize(test_image,(128,128))\n",
    "    test_image = np.array(test_image)\n",
    "    test_image = test_image.astype('float32')\n",
    "    test_image /= 255\n",
    "    print (test_image.shape)\n",
    "\n",
    "    if num_channels==1:\n",
    "        if K.image_dim_ordering()=='th':\n",
    "            test_image= np.expand_dims(test_image, axis=1)\n",
    "            print (test_image.shape)\n",
    "\n",
    "        else:\n",
    "            test_image= np.expand_dims(test_image, axis=4) \n",
    "            print (test_image.shape)\n",
    "\n",
    "    else:\n",
    "        if K.image_dim_ordering()=='th':\n",
    "            test_image=np.rollaxis(test_image,3,1)\n",
    "            print (test_image.shape)\n",
    "        else:\n",
    "            test_image= np.expand_dims(test_image, axis=0)\n",
    "            print (test_image.shape)\n",
    "\n",
    "    # Predicting the test image\n",
    "    print(model.predict(test_image))\n",
    "    predict_class=model.predict_classes(test_image)\n",
    "    print(predict_class)\n",
    "\n",
    "    result=''\n",
    "\n",
    "    if predict_class==[1]:\n",
    "        print('Result : => Positive Hand Gesture')\n",
    "        result='Positive Hand Gesture'\n",
    "\n",
    "    elif predict_class==[0]:\n",
    "        print('Result : => Negative Hand Gesture')\n",
    "        result='Negative Hand Gesture'\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def capture_HG_image():\n",
    "\n",
    "    cam=cv2.VideoCapture(0)\n",
    "    \n",
    "    save = 'C:/Users/Nipuni/AnacondaProjects/Indoor_Object_Identification_System/IOIM/Original/Test'\n",
    "\n",
    "    cv2.namedWindow(\"test\")\n",
    "\n",
    "    img_counter=0\n",
    "\n",
    "    while True:\n",
    "        ret, frame=cam.read()\n",
    "        cv2.imshow(\"test\",frame)\n",
    "        if not ret:\n",
    "            break\n",
    "        k=cv2.waitKey(1)\n",
    "\n",
    "        if k%256 == 27:\n",
    "            #ESC pressed\n",
    "            print(\"Escape hit, closing...\")\n",
    "            break\n",
    "        elif k%256 == 32:\n",
    "            #SPACE pressed\n",
    "            img_name=\"hand_gesture_{}.png\".format(img_counter)\n",
    "            \n",
    "            return_value, image = cam.read()\n",
    "            \n",
    "            cv2.imwrite(os.path.join(save, img_name), image)\n",
    "\n",
    "            print(\"{} written!\".format(img_name))\n",
    "\n",
    "            img_counter +=1\n",
    "\n",
    "    cam.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def capture_IO_image():\n",
    "\n",
    "    cam=cv2.VideoCapture(0)\n",
    "\n",
    "    save = 'C:/Users/Nipuni/AnacondaProjects/Indoor_Object_Identification_System/IOIM/Indoor Objects/Test'\n",
    "\n",
    "    cv2.namedWindow(\"test\")\n",
    "\n",
    "    img_counter=0\n",
    "\n",
    "    while True:\n",
    "        ret, frame=cam.read()\n",
    "        cv2.imshow(\"test\",frame)\n",
    "        if not ret:\n",
    "            break\n",
    "        k=cv2.waitKey(1)\n",
    "\n",
    "        if k%256 == 27:\n",
    "            #ESC pressed\n",
    "            print(\"Escape hit, closing...\")\n",
    "            break\n",
    "        elif k%256 == 32:\n",
    "            #SPACE pressed\n",
    "            img_name=\"indoor_object_{}.png\".format(img_counter)\n",
    "            \n",
    "            return_value, image = cam.read()\n",
    "            \n",
    "            cv2.imwrite(os.path.join(save, img_name), image)\n",
    "\n",
    "            print(\"{} written!\".format(img_name))\n",
    "\n",
    "            img_counter +=1\n",
    "\n",
    "    cam.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Capture image of the object from the camera\n",
    "def capture_Object(output):\n",
    "    \n",
    "    #Checking whether the captured hand gesture is a valid hand gesture to track the object\n",
    "    if output=='Positive Hand Gesture':\n",
    "        \n",
    "        capture_image()\n",
    "                    \n",
    "        print(\"Taking image...\")\n",
    "\n",
    "    else :\n",
    "        print('Hand Gesture is not suitable for tracking the object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_object_class(path):\n",
    "\n",
    "    # Predicting the test image\n",
    "    test_image = cv2.imread(path)\n",
    "    test_image=cv2.resize(test_image,(128,128))\n",
    "    test_image = np.array(test_image)\n",
    "    test_image = test_image.astype('float32')\n",
    "    test_image /= 255\n",
    "    #print (test_image.shape)\n",
    "\n",
    "    if num_channels==1:\n",
    "        if K.image_dim_ordering()=='th':\n",
    "            test_image= np.expand_dims(test_image, axis=1)\n",
    "            #print (test_image.shape)\n",
    "\n",
    "        else:\n",
    "            test_image= np.expand_dims(test_image, axis=4) \n",
    "            #print (test_image.shape)\n",
    "\n",
    "    else:\n",
    "        if K.image_dim_ordering()=='th':\n",
    "            test_image=np.rollaxis(test_image,3,1)\n",
    "            #print (test_image.shape)\n",
    "        else:\n",
    "            test_image= np.expand_dims(test_image, axis=0)\n",
    "            #print (test_image.shape)\n",
    "\n",
    "    # Predicting the test image\n",
    "    print(model.predict(test_image))\n",
    "    predict_class=model.predict_classes(test_image)\n",
    "    #print(predict_class)\n",
    "    return predict_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand_gesture_0.png written!\n",
      "Escape hit, closing...\n",
      "(128, 128, 3)\n",
      "(1, 128, 128, 3)\n",
      "[[ 0.33328965  0.66671038]]\n",
      "1/1 [==============================] - 0s\n",
      "[1]\n",
      "Result : => Positive Hand Gesture\n",
      "indoor_object_0.png written!\n",
      "Escape hit, closing...\n",
      "[[ 0.31537867  0.68462127]]\n",
      "1/1 [==============================] - 0s\n",
      "This is a Mug\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "hand_gesture=capture_HG_image()\n",
    "\n",
    "hand_prediction=Get_Reult_Of_HG(filepath='Original/Test/hand_gesture_0.png')\n",
    "\n",
    "\n",
    "if hand_prediction =='Positive Hand Gesture':\n",
    "    indoor_object=capture_IO_image()\n",
    "    \n",
    "    path=os.path.abspath(indoor_object)\n",
    "    \n",
    "    prediction=predict_object_class(path='Indoor Objects/Test/indoor_object_0.png')\n",
    "\n",
    "    if prediction==[0]:\n",
    "        print('This is a Bottel')\n",
    "    elif prediction==[1]:\n",
    "        print ('This is a Mug')\n",
    "else :\n",
    "    print('Hand Gesture is not suitable for tracking the object')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
